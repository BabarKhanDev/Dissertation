{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71446870",
   "metadata": {
    "executionInfo": {
     "elapsed": 501,
     "status": "ok",
     "timestamp": 1678040508046,
     "user": {
      "displayName": "Babar Khan",
      "userId": "05718637171689929979"
     },
     "user_tz": 0
    },
    "id": "71446870"
   },
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.utils.data\n",
    "from torchvision import transforms\n",
    "from torch.nn.functional import interpolate\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "import numpy as np\n",
    "from natsort import natsorted\n",
    "from PIL import Image\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ygiijE4-_wu7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26753,
     "status": "ok",
     "timestamp": 1678040358879,
     "user": {
      "displayName": "Babar Khan",
      "userId": "05718637171689929979"
     },
     "user_tz": 0
    },
    "id": "ygiijE4-_wu7",
    "outputId": "4581a748-0492-4cea-c767-90a688340ee4"
   },
   "outputs": [],
   "source": [
    "# Code to upload dataset to google colab\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kJIKcaEA_3xs",
   "metadata": {
    "executionInfo": {
     "elapsed": 6654,
     "status": "ok",
     "timestamp": 1678040365519,
     "user": {
      "displayName": "Babar Khan",
      "userId": "05718637171689929979"
     },
     "user_tz": 0
    },
    "id": "kJIKcaEA_3xs"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "path_to_zip_file = 'drive/MyDrive/data.zip'\n",
    "directory_to_extract_to = 'data/'\n",
    "with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n",
    "    zip_ref.extractall(directory_to_extract_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eB8s5Ykh_mRq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 417,
     "status": "ok",
     "timestamp": 1678045335205,
     "user": {
      "displayName": "Babar Khan",
      "userId": "05718637171689929979"
     },
     "user_tz": 0
    },
    "id": "eB8s5Ykh_mRq",
    "outputId": "454f1072-ed46-4cf8-fbe0-9042ea9b4bf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280 Items in Train dataset\n",
      "320  Items in Test dataset\n"
     ]
    }
   ],
   "source": [
    "class VISCHEMA_PLUS(Dataset):\n",
    "    def __init__(self, image_dir = 'VISCHEMA_PLUS/images', label_dir = 'VISCHEMA_PLUS/vms', transform = None):\n",
    "        self.transform = transform\n",
    "        \n",
    "        self.image_dir = image_dir\n",
    "        self.label_dir = label_dir\n",
    "        \n",
    "        all_images = os.listdir(image_dir)\n",
    "        self.all_images = natsorted(all_images)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.all_images)\n",
    "\n",
    "    def __getitem__(self, idx):    \n",
    "        convert_tensor = transforms.ToTensor()\n",
    "        \n",
    "        image = Image.open(f\"{self.image_dir}/{self.all_images[idx]}\").convert(\"RGB\")\n",
    "        image = convert_tensor(image)\n",
    "\n",
    "        label = Image.open(f\"{self.label_dir}/{self.all_images[idx]}\").convert(\"RGB\")\n",
    "        label = convert_tensor(label)\n",
    "        \n",
    "        if self.transform != None:\n",
    "            image = self.transform(image)\n",
    "            label = self.transform(label)\n",
    "            \n",
    "        return image, label\n",
    "\n",
    "# I have resized the images to 512x512 as this will make designing the model easier.\n",
    "image_transforms = transforms.Compose([\n",
    "    transforms.Resize(128),\n",
    "    transforms.Normalize(0.5,0.5)\n",
    "])\n",
    "        \n",
    "dataset = VISCHEMA_PLUS(transform = image_transforms)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "batch_size = 2\n",
    "train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle=True)\n",
    "\n",
    "print(f'{len(train_dataset)} Items in Train dataset')\n",
    "print(f'{len(test_dataset)}  Items in Test dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44d4c2b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 5192,
     "status": "ok",
     "timestamp": 1678045344684,
     "user": {
      "displayName": "Babar Khan",
      "userId": "05718637171689929979"
     },
     "user_tz": 0
    },
    "id": "f44d4c2b",
    "outputId": "2fd9a93d-093e-4837-808a-7027ca079a1b"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "figure = plt.figure(figsize=(15,15))\n",
    "cols, rows = 3, 4\n",
    "for i in range(rows):\n",
    "    \n",
    "    images, labels = next(iter(train_loader))\n",
    "    \n",
    "    # The image\n",
    "    figure.add_subplot(rows,cols, cols*i+1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow((images[0].squeeze().permute(1, 2, 0) +1 )/2 )\n",
    "    \n",
    "    # The Label\n",
    "    figure.add_subplot(rows,cols, cols*i+2)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow((labels[0].squeeze().permute(1, 2, 0) +1 )/2)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8250e91e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1861,
     "status": "ok",
     "timestamp": 1678045561416,
     "user": {
      "displayName": "Babar Khan",
      "userId": "05718637171689929979"
     },
     "user_tz": 0
    },
    "id": "8250e91e",
    "outputId": "efe6d8dd-e97c-46a1-8b9c-958e5245dbc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7703107 Parameters in UNet Generator\n",
      "torch.Size([2, 3, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(in_channels,out_channels,3,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.Conv2d(out_channels,out_channels,3,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.main(x)\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, channels=(3,64,128,256,512)):\n",
    "        super().__init__()\n",
    "        self.encoding_blocks = nn.ModuleList(\n",
    "            [Block(channels[i], channels[i+1]) for i in range(len(channels)-1)]\n",
    "        )\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = []\n",
    "        \n",
    "        for block in self.encoding_blocks:\n",
    "            x = block(x)\n",
    "            features.append(x)\n",
    "            x = self.pool(x)\n",
    "                 \n",
    "        return features\n",
    "        \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, channels=(512,256,128,64)):\n",
    "        super().__init__()\n",
    "        self.channels = channels\n",
    "        self.upconvs = nn.ModuleList([nn.ConvTranspose2d(self.channels[i], self.channels[i+1],2,2) for i in range(len(channels)-1)])\n",
    "        self.decoder_blocks = nn.ModuleList(\n",
    "            [Block(channels[i], channels[i+1]) for i in range(len(channels)-1)]\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, encoder_features):\n",
    "        for i in range(len(self.channels)-1):\n",
    "            x = self.upconvs[i](x)\n",
    "            features = self.crop(encoder_features[i], x)\n",
    "            x = torch.cat([x, features], dim=1)\n",
    "            x = self.decoder_blocks[i](x)\n",
    "        return x\n",
    "    \n",
    "    def crop(self, features, x):\n",
    "        _, _, height, width = x.shape\n",
    "        features = transforms.CenterCrop([height, width])(features)\n",
    "        return features\n",
    "        \n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, \n",
    "                 encode_channels=(3,64,128,256,512), \n",
    "                 decode_channels=(512,256,128,64), \n",
    "                 num_class=3, \n",
    "                 retain_dim=True, \n",
    "                 output_size=(572,572)):\n",
    "        \n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.encoder = Encoder(encode_channels)\n",
    "        self.decoder = Decoder(decode_channels)\n",
    "        \n",
    "        self.head = nn.Conv2d(decode_channels[-1], num_class, 1)\n",
    "        \n",
    "        \"\"\"# Initialize weights\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.ConvTranspose2d):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\"\"\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        encoding_features = self.encoder(x)\n",
    "        decoding_features = self.decoder(encoding_features[::-1][0], encoding_features[::-1][1:])\n",
    "        output = self.head(decoding_features)\n",
    "        output = nn.Tanh()(output)\n",
    "        \n",
    "        return output\n",
    "\n",
    "model = Generator()\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'{total_params} Parameters in UNet Generator')\n",
    "\n",
    "images, _ = next(iter(train_loader))\n",
    "output = model(images)\n",
    "print(output.shape)\n",
    "\n",
    "del model, output, images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fac8e069",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1678045626648,
     "user": {
      "displayName": "Babar Khan",
      "userId": "05718637171689929979"
     },
     "user_tz": 0
    },
    "id": "fac8e069",
    "outputId": "0a4f48ad-eccb-4eff-d49d-899696208e35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6965440 Parameters in Discriminator\n",
      "torch.Size([2, 1, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        def block(in_channels, out_channels, norm=True):\n",
    "            layers = [nn.Conv2d(in_channels, out_channels, 4,stride=2, padding=1)]\n",
    "            if norm:\n",
    "                layers.append(nn.BatchNorm2d(out_channels))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            *block(6, 64, norm = False),\n",
    "            *block(64, 128),\n",
    "            *block(128,256),\n",
    "            *block(256,512),\n",
    "            *block(512,512),\n",
    "            nn.ZeroPad2d((1,0,1,0)),\n",
    "            nn.Conv2d(512,1,4,padding=1, bias=False)\n",
    "        )\n",
    "        \n",
    "    def forward(self, images, labels):\n",
    "        \n",
    "        image_input = torch.cat((images, labels), 1)\n",
    "        return self.model(image_input)\n",
    "\n",
    "model = Discriminator()\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'{total_params} Parameters in Discriminator')\n",
    "\n",
    "images, labels = next(iter(train_loader))\n",
    "output = model(images, labels)\n",
    "print(output.shape)\n",
    "\n",
    "del model, output, images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46b592fa",
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1678047533567,
     "user": {
      "displayName": "Babar Khan",
      "userId": "05718637171689929979"
     },
     "user_tz": 0
    },
    "id": "46b592fa"
   },
   "outputs": [],
   "source": [
    "# Set up our training environment\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "patch = (1, 4, 4)\n",
    "\n",
    "net_G = Generator()\n",
    "net_D = Discriminator()\n",
    "\n",
    "net_G, net_D = net_G.to(device), net_D.to(device)\n",
    "\n",
    "criterion_GAN = nn.MSELoss()\n",
    "criterion_pixelwise = nn.L1Loss() \n",
    "\n",
    "# Loss weight of L1 pixel-wise loss between translated image and real image\n",
    "# This value is copied from the PIX2PIX architecture\n",
    "lambda_pixel = 100\n",
    "\n",
    "optim_G = torch.optim.Adam(net_G.parameters(), lr=0.0001, betas = (0,0.9))\n",
    "optim_D = torch.optim.Adam(net_D.parameters(), lr=0.0001, betas = (0,0.9))\n",
    "num_epochs = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e25d505",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2689672,
     "status": "error",
     "timestamp": 1678050260282,
     "user": {
      "displayName": "Babar Khan",
      "userId": "05718637171689929979"
     },
     "user_tz": 0
    },
    "id": "9e25d505",
    "outputId": "ed3be77a-a1c9-4e61-f8f2-0d96bc70a5a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n",
      "Testing\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 8.00 GiB total capacity; 7.27 GiB already allocated; 0 bytes free; 7.29 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10120\\1806303391.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0mimages_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreal_labels_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimages_t\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreal_labels_t\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[0mfake_label_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet_G\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m         \u001b[0mloss_pixel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion_pixelwise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfake_label_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreal_labels_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[0mtotal_test_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss_pixel\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mimages_t\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10120\\3432489131.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[0mencoding_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m         \u001b[0mdecoding_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoding_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecoding_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10120\\3432489131.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding_blocks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m             \u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10120\\3432489131.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     11\u001b[0m         )\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 463\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    464\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    457\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m--> 459\u001b[1;33m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[0;32m    460\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 8.00 GiB total capacity; 7.27 GiB already allocated; 0 bytes free; 7.29 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ScJme93_IB2E",
   "metadata": {
    "executionInfo": {
     "elapsed": 674,
     "status": "ok",
     "timestamp": 1678050264873,
     "user": {
      "displayName": "Babar Khan",
      "userId": "05718637171689929979"
     },
     "user_tz": 0
    },
    "id": "ScJme93_IB2E"
   },
   "outputs": [],
   "source": [
    "torch.save(net_D.state_dict(), f'weights-NETD-1-{epoch}.pkl')\n",
    "torch.save(net_G.state_dict(), f'weights-NETG-1-{epoch}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZBTBV_S_PJA2",
   "metadata": {
    "id": "ZBTBV_S_PJA2"
   },
   "outputs": [],
   "source": [
    "# Visualise Output\n",
    "\n",
    "net_G = Generator()\n",
    "net_G.load_state_dict(torch.load(\"weights-NETG-1-48.pkl\", map_location=torch.device('cpu')), strict=False)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "images, labels = next(iter(train_loader))\n",
    "figure = plt.figure(figsize=(15,15))\n",
    "output = net_G(images)\n",
    "\n",
    "cols, rows = 3, 4\n",
    "for i in range(rows):\n",
    "\n",
    "    figure.add_subplot(rows,cols, cols*i+1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow((images[i].cpu().detach().squeeze().permute(1, 2, 0) +1 )/ 2 )\n",
    "    \n",
    "    figure.add_subplot(rows,cols, cols*i+2)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow((output[i].cpu().detach().squeeze().permute(1, 2, 0) +1 )/ 2 )  \n",
    "\n",
    "    figure.add_subplot(rows,cols, cols*i+3)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow((labels[i].cpu().detach().squeeze().permute(1, 2, 0) +1 )/ 2 )\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
